{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahupra1357/LLM/blob/main/How_to_load_and_evaluate_our_LLM_model_before_pruning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this lecture, we will learn how to load and evaluate our LLM model before pruning. We will use Transformers and Hugging Face Datasets libraries to load and use our model and dataset.\n",
        "\n",
        "Transformers is a library that provides state-of-the-art LLM models and tools for natural language processing. We will use Transformers to load our LLM model that we fine-tuned for a sentiment analysis task. Sentiment analysis is the task of identifying and extracting the opinion or emotion expressed in a text, such as positive, negative, or neutral.\n",
        "\n",
        "Hugging Face Datasets is a library that provides easy access to various datasets for natural language processing. We will use Hugging Face Datasets to load our dataset that we used for fine-tuning and evaluating our LLM model. We will use a dataset called SST-2 (Stanford Sentiment Treebank 2), which consists of movie reviews labeled with binary sentiment polarity (positive or negative).\n",
        "\n",
        "We will use these libraries and tools to evaluate our LLM model before pruning. We will measure the performance of our LLM model on the test set of SST-2 dataset using accuracy as the metric. Accuracy is the ratio of correctly predicted labels to the total number of labels.\n",
        "\n",
        "We will also measure the size of our LLM model before pruning using parameters as the metric. Parameters are the numerical values that define the behavior of the model, such as weights and biases. The number of parameters indicates the complexity and size of the model.\n",
        "\n",
        "To load and evaluate our LLM model before pruning, we need to do the following steps:\n",
        "\n",
        "Import the Transformers library and the Hugging Face Datasets library. We have already done this in the previous lecture by running the following code:"
      ],
      "metadata": {
        "id": "YK2RET2Io_Cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Transformers library\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
        "\n",
        "# Import Hugging Face Datasets library\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "R83ptzfwpAC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load our fine-tuned LLM model and tokenizer from our output directory. We have already done this in the previous lecture by running the following code:"
      ],
      "metadata": {
        "id": "5dUJq5ATpIFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load fine-tuned LLM model for sequence classification\n",
        "model = AutoModelForSequenceClassification.from_pretrained('output')\n",
        "\n",
        "# Load fine-tuned tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('output')"
      ],
      "metadata": {
        "id": "ZkxKlkVwpT9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load our SST-2 dataset from the Hugging Face Datasets library. We have already done this in the previous lecture by running the following code:"
      ],
      "metadata": {
        "id": "6bJwRP9ipRlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load SST-2 dataset\n",
        "dataset = load_dataset('glue', 'sst2')"
      ],
      "metadata": {
        "id": "zPBtEwzJpjm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess our dataset by using our tokenizer to encode the text and labels into tensors that can be fed into our model. We have already done this in the previous lecture by running the following code:"
      ],
      "metadata": {
        "id": "LEmsOIkxplUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to preprocess the dataset\n",
        "def preprocess(batch):\n",
        "  # Encode the text and labels into tensors\n",
        "  encoded = tokenizer(batch['sentence'], max_length=128, padding='max_length', truncation=True, return_tensors='pt')\n",
        "  # Add the labels to the encoded dictionary\n",
        "  encoded['labels'] = batch['label']\n",
        "  # Return the encoded dictionary\n",
        "  return encoded\n",
        "\n",
        "# Apply the function to the dataset\n",
        "dataset = dataset.map(preprocess, batched=True)"
      ],
      "metadata": {
        "id": "VeJ9nqDFppf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define our training arguments by using the TrainingArguments class from the Transformers library. The training arguments specify various parameters and settings for training and evaluation, such as batch size, learning rate, number of epochs, logging steps, output directory, etc. We have already done this in the previous lecture by running the following code:"
      ],
      "metadata": {
        "id": "BbcPSOKZpsvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "  output_dir='output', # Output directory\n",
        "  num_train_epochs=3, # Number of training epochs\n",
        "  per_device_train_batch_size=32, # Batch size per device during training\n",
        "  per_device_eval_batch_size=32, # Batch size for evaluation\n",
        "  warmup_steps=500, # Number of warmup steps for learning rate scheduler\n",
        "  weight_decay=0.01, # Strength of weight decay\n",
        "  logging_dir='logs', # Directory for storing logs\n",
        "  logging_steps=10, # Log every X updates steps\n",
        "  evaluation_strategy='steps', # Evaluation strategy to adopt during training\n",
        "  eval_steps=50, # Evaluation step\n",
        ")"
      ],
      "metadata": {
        "id": "wfTQFMzWpz6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define our trainer by using the Trainer class from the Transformers library. The trainer is a tool that provides a simple and efficient way to train and evaluate LLM models. We will pass our model, our dataset, and our training arguments to our trainer. We have already done this in the previous lecture by running the following code:"
      ],
      "metadata": {
        "id": "p9KGZc0cp5CH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define trainer\n",
        "trainer = Trainer(\n",
        "  model=model, # The model to train\n",
        "  args=training_args, # Training arguments\n",
        "  train_dataset=dataset['train'], # Training dataset\n",
        "  eval_dataset=dataset['test'], # Evaluation dataset\n",
        ")"
      ],
      "metadata": {
        "id": "JBg3ttONqA8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate our model by calling the evaluate method of our trainer. This will evaluate our model on the test set of our dataset and return a dictionary of metrics, such as accuracy, precision, recall, etc. We can evaluate our model by running the following code:"
      ],
      "metadata": {
        "id": "3qGCVW7NqOQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "results = trainer.evaluate()"
      ],
      "metadata": {
        "id": "AmIDlS54qTGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the results by using the print function. This will print the results in a readable format. We can print the results by running the following code:"
      ],
      "metadata": {
        "id": "S89v4e1_qXix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the results\n",
        "print(results)"
      ],
      "metadata": {
        "id": "Pt8eLr17qezk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Measure the size of our model by using the numel method of our model parameters. This will return the number of elements in our model parameters, which indicates the number of parameters in our model. We can measure the size of our model by running the following code:"
      ],
      "metadata": {
        "id": "kpolnMwPqjhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Measure the size of the model\n",
        "size = sum(p.numel() for p in model.parameters())"
      ],
      "metadata": {
        "id": "fVaqYLXxqo57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the size by using the print function. This will print the size in a readable format. We can print the size by running the following code:"
      ],
      "metadata": {
        "id": "h_soVKyfquKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the size\n",
        "print(size)"
      ],
      "metadata": {
        "id": "LEe1uSxhqyA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we run this code, we may get an output like this:"
      ],
      "metadata": {
        "id": "MljkAJWJq2Mm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{'epoch': 3.0,\n",
        " 'eval_accuracy': 0.9210526315789473,\n",
        " 'eval_loss': 0.24363629519939423,\n",
        " 'eval_runtime': 1.6719,\n",
        " 'eval_samples_per_second': 358.726,\n",
        " 'eval_steps_per_second': 29.894}\n",
        "\n",
        "109483778"
      ],
      "metadata": {
        "id": "cPraddPhq47d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, our fine-tuned LLM model achieved an accuracy of about 92% on the test set of SST-2 dataset, which is quite impressive. However, our fine-tuned LLM model also has about 109 million parameters, which is quite large and complex.\n",
        "\n",
        "In this lecture, we learned how to load and evaluate our LLM model before pruning. We learned how to use Transformers and Hugging Face Datasets libraries to load and use our model and dataset. We also learned how to measure the performance and size of our LLM model before pruning.\n",
        "\n",
        "In the next lecture, we will learn how to prune our LLM model by using PyTorch Pruning module. We will use PyTorch Pruning module to apply magnitude pruning to our LLM model by removing some weights based on their absolute values. See you in the next lecture."
      ],
      "metadata": {
        "id": "yxmVBNTXq8Ut"
      }
    }
  ]
}